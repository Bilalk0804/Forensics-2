"""
Malware Detection Pipeline Module
Machine learning-based malware analysis for PE headers and URLs.

Detects executable malware using:
1. PE Header Feature Extraction (for .exe, .dll files)
2. URL Malware Detection (Logistic Regression with TF-IDF)

Classifiers stored in MODELS/Malware-Detection-using-Machine-learning/Classifier/
"""

import json
import logging
import os
import re
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path

try:
    import pefile
    PEFILE_AVAILABLE = True
except ImportError:
    PEFILE_AVAILABLE = False

try:
    import pickle
    import joblib
    from sklearn.feature_extraction.text import TfidfVectorizer
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

from .interface import AnalyzerInterface

logger = logging.getLogger("SENTINEL_MALWARE")

# PE Extensions to analyze for malware
PE_EXTENSIONS = frozenset({'.exe', '.dll', '.sys', '.scr', '.drv', '.bin'})

# Risk classification for malware detections
MALWARE_RISK_LEVELS = {
    'malicious': 'HIGH',
    'bad': 'HIGH',
    'suspicious': 'MEDIUM',
    'benign': 'LOW',
    'good': 'LOW'
}


class MalwarePipeline(AnalyzerInterface):
    """
    Malware analyzer using ML classifiers for PE headers and URLs.
    
    Lifecycle (called by main.py):
        malware_analyzer = MalwarePipeline(db)
        malware_analyzer.run()
    """

    PIPELINE_NAME = "malware_pipeline"

    def __init__(self, db, classifiers_path: Optional[str] = None):
        """
        Initialize the malware pipeline.

        Args:
            db: DatabaseHandler instance for reading files and writing artifacts.
            classifiers_path: Override path to classifiers directory.
                            Defaults to MODELS/Malware-Detection-using-Machine-learning/Classifier/
        """
        try:
            from config import (
                PROJECT_ROOT,
                DOCKER_ENABLED,
                DOCKER_MALWARE_IMAGE,
                DOCKER_TIMEOUT,
            )
        except Exception:
            from src.config import (  # type: ignore
                PROJECT_ROOT,
                DOCKER_ENABLED,
                DOCKER_MALWARE_IMAGE,
                DOCKER_TIMEOUT,
            )

        self.db = db
        self.classifiers_path = classifiers_path or os.path.join(
            PROJECT_ROOT, "MODELS", "Malware-Detection-using-Machine-learning", "Classifier"
        )

        # Initialize classifiers
        self.pe_classifier = None  # PE Random Forest classifier
        self.pe_features = None    # Important features for PE classifier
        self.url_classifier = None # URL Logistic Regression classifier
        self.url_vectorizer = None # TF-IDF vectorizer for URLs

        # Validation flags
        self.pe_ready = False
        self.url_ready = False

        # Docker settings
        self.docker_enabled = DOCKER_ENABLED
        self.docker_image = DOCKER_MALWARE_IMAGE
        self.docker_timeout = DOCKER_TIMEOUT
        self.docker_available = False
        self.use_docker_for_pe = False
        self.use_docker_for_url = False

    # ------------------------------------------------------------------
    # AnalyzerInterface implementation
    # ------------------------------------------------------------------

    def validate(self) -> bool:
        """
        Validate that the malware classifiers can be loaded.

        Returns:
            True if at least one classifier is available.

        Raises:
            ImportError: if required packages are missing.
        """
        if not SKLEARN_AVAILABLE:
            raise ImportError("scikit-learn required for malware detection")

        # Load PE classifier
        try:
            pe_classifier_path = os.path.join(self.classifiers_path, "classifier.pkl")
            pe_features_path = os.path.join(self.classifiers_path, "features.pkl")

            if os.path.exists(pe_classifier_path) and os.path.exists(pe_features_path):
                with open(pe_classifier_path, 'rb') as f:
                    self.pe_classifier = pickle.load(f)
                with open(pe_features_path, 'rb') as f:
                    self.pe_features = pickle.load(f)
                self.pe_ready = True
                logger.info("PE malware classifier loaded successfully")
            else:
                logger.warning(f"PE classifier files not found at {self.classifiers_path}")
        except Exception as e:
            logger.warning(f"Failed to load PE classifier: {e}")

        # Load URL classifier
        try:
            url_classifier_path = os.path.join(self.classifiers_path, "pickel_model.pkl")
            url_vectorizer_path = os.path.join(self.classifiers_path, "pickel_vector.pkl")

            if os.path.exists(url_classifier_path) and os.path.exists(url_vectorizer_path):
                with open(url_classifier_path, 'rb') as f:
                    self.url_classifier = pickle.load(f)
                with open(url_vectorizer_path, 'rb') as f:
                    self.url_vectorizer = pickle.load(f)
                self.url_ready = True
                logger.info("URL malware classifier loaded successfully")
            else:
                logger.warning(f"URL classifier files not found at {self.classifiers_path}")
        except Exception as e:
            logger.warning(f"Failed to load URL classifier: {e}")

        if self.docker_enabled:
            from core.docker_runner import is_docker_available

            self.docker_available = is_docker_available()
            if self.docker_available:
                if not self.pe_ready:
                    self.pe_ready = True
                    self.use_docker_for_pe = True
                if not self.url_ready:
                    self.url_ready = True
                    self.use_docker_for_url = True
            else:
                logger.warning("Docker enabled but not available")

        if not (self.pe_ready or self.url_ready):
            logger.error("No malware classifiers available")
            return False

        logger.info("Malware pipeline validation passed")
        return True

    def analyze(self, data):
        """
        Analyze data for malware indicators.
        
        Args:
            data: Can be a file path (str), URL (str), or dict with 'type' and 'content' keys
            
        Returns:
            dict: Analysis results with malware detection findings
        """
        if isinstance(data, dict):
            data_type = data.get('type', 'unknown')
            content = data.get('content', '')
            
            if data_type == 'url':
                return self._analyze_url_content(content)
            elif data_type == 'pe':
                return self._analyze_pe_content(content)
        elif isinstance(data, str):
            if data.startswith('http://') or data.startswith('https://'):
                return self._analyze_url_content(data)
            elif os.path.exists(data):
                if data.lower().endswith(('.exe', '.dll', '.sys')):
                    return self._analyze_pe_file(data)
        
        return {'error': 'Unsupported data type for malware analysis'}

    def _analyze_url_content(self, url: str):
        """Analyze a single URL for malware."""
        if self.use_docker_for_url:
            return self._analyze_url_with_docker(url)
        if not self.url_ready:
            return {'error': 'URL classifier not loaded'}
        
        try:
            url_vector = self.url_vectorizer.transform([url])
            prediction = self.url_classifier.predict(url_vector)[0]
            probability = self.url_classifier.predict_proba(url_vector)[0]
            
            return {
                'type': 'url',
                'content': url,
                'malicious': bool(prediction),
                'confidence': float(max(probability)),
                'status': 'malicious' if prediction else 'safe'
            }
        except Exception as e:
            logger.error(f"URL analysis failed: {e}")
            return {'error': str(e)}

    def _analyze_pe_file(self, file_path: str):
        """Analyze a single PE file for malware."""
        if self.use_docker_for_pe:
            return self._analyze_pe_with_docker(file_path)
        if not self.pe_ready:
            return {'error': 'PE classifier not loaded'}
        
        try:
            features = self._extract_pe_features(file_path)
            if not features:
                return {'error': 'Failed to extract PE features'}
            
            if getattr(self, "pe_features", None):
                feature_vector = [features.get(feat, 0) for feat in self.pe_features]
            else:
                feature_vector = [features[key] for key in sorted(features.keys())]
            
            prediction = self.pe_classifier.predict([feature_vector])[0]
            probability = self.pe_classifier.predict_proba([feature_vector])[0]
            
            return {
                'type': 'pe',
                'file_path': file_path,
                'malicious': bool(prediction),
                'confidence': float(max(probability)),
                'status': 'malicious' if prediction else 'safe',
                'features': features
            }
        except Exception as e:
            logger.error(f"PE analysis failed for {file_path}: {e}")
            return {'error': str(e)}

    def _analyze_pe_content(self, content):
        """Analyze PE file content (raw bytes or base64)."""
        import tempfile

        if isinstance(content, str):
            import base64
            try:
                content = base64.b64decode(content)
            except Exception:
                return {'error': 'PE content must be raw bytes or base64-encoded string'}

        if not isinstance(content, (bytes, bytearray)):
            return {'error': 'PE content must be bytes'}

        # Write to temp file so _analyze_pe_file can process it
        try:
            with tempfile.NamedTemporaryFile(suffix='.exe', delete=False) as tmp:
                tmp.write(content)
                tmp_path = tmp.name

            result = self._analyze_pe_file(tmp_path)
            os.unlink(tmp_path)
            return result
        except Exception as e:
            logger.error(f"PE content analysis failed: {e}")
            return {'error': str(e)}

    def run(self):
        """
        Main entry point for malware detection pipeline.
        Processes pending files and extracts malware indicators.
        """
        # Validate without failing - gracefully degrade if validators unavailable
        validation_result = self.validate()
        
        if not (self.pe_ready or self.url_ready):
            logger.warning("No malware classifiers available - skipping malware detection")
            return 0

        logger.info(">>> MALWARE PIPELINE: Starting analysis")

        results = 0
        # Analyze PE files (executables)
        if self.pe_ready:
            try:
                results += self._analyze_pe_files() or 0
            except Exception as e:
                logger.error(f"PE file analysis failed: {e}")

        # Analyze URLs extracted from all processed files
        if self.url_ready:
            try:
                results += self._analyze_urls() or 0
            except Exception as e:
                logger.error(f"URL analysis failed: {e}")

        logger.info(">>> MALWARE PIPELINE: Complete ({} threats found)".format(results))
        return results

    # ------------------------------------------------------------------
    # PE File Analysis
    # ------------------------------------------------------------------

    def _analyze_pe_files(self):
        """Query database for executable files and analyze them."""
        if not self.pe_ready:
            logger.debug("PE analysis not ready, skipping")
            return 0
            
        conn = self.db.get_connection()
        cursor = conn.cursor()
        threats_found = 0

        try:
            # Get all executable files
            cursor.execute('''
                SELECT file_id, file_path, file_hash FROM files
                WHERE mime_type LIKE 'application/x-executable%'
                   OR mime_type LIKE 'application/x-msdos%'
                   OR file_path LIKE '%.exe'
                   OR file_path LIKE '%.dll'
                   OR file_path LIKE '%.sys'
                ORDER BY file_id
            ''')

            pe_files = cursor.fetchall()
            if not pe_files:
                logger.debug("No PE files found for analysis")
                return 0
                
            logger.info(f"Found {len(pe_files)} PE files to analyze")

            for file_id, file_path, file_hash in pe_files:
                try:
                    if os.path.exists(file_path):
                        result = self._analyze_single_pe(file_id, file_path, file_hash)
                        if result:
                            threats_found += 1
                except Exception as e:
                    logger.debug(f"Failed to analyze {file_path}: {e}")

        except Exception as e:
            logger.error(f"PE file query failed: {e}")
        finally:
            conn.close()
            
        return threats_found

    def _analyze_single_pe(self, file_id: int, file_path: str, file_hash: str):
        """Analyze a single PE file for malware indicators."""
        if self.use_docker_for_pe:
            return self._analyze_single_pe_with_docker(file_id, file_path, file_hash)
        if not PEFILE_AVAILABLE:
            logger.warning("pefile library not available, skipping PE analysis")
            return

        try:
            # Extract PE header features
            features_dict = self._extract_pe_features(file_path)
            if not features_dict:
                return

            # Prepare feature vector in correct order
            feature_vector = [features_dict.get(feat, 0) for feat in self.pe_features]
            feature_vector = [feature_vector]  # Reshape for classifier

            # Predict malware
            prediction = self.pe_classifier.predict(feature_vector)[0]
            confidence = max(self.pe_classifier.predict_proba(feature_vector)[0])

            risk_level = MALWARE_RISK_LEVELS.get(str(prediction).lower(), 'MEDIUM')

            # Store artifact
            artifact_data = {
                "detection_type": "PE_MALWARE",
                "classification": str(prediction),
                "confidence": float(confidence),
                "file_hash": file_hash,
                "features_analyzed": len(self.pe_features)
            }

            self._store_artifact(
                file_id,
                risk_level,
                f"PE Malware Detection: {prediction} (confidence: {confidence:.2f})",
                artifact_data
            )

            logger.info(
                f"PE Analysis: {Path(file_path).name} -> {prediction} (confidence: {confidence:.2f})"
            )

        except Exception as e:
            logger.error(f"PE feature extraction failed for {file_path}: {e}")

    def _extract_pe_features(self, file_path: str) -> Optional[Dict[str, Any]]:
        """
        Extract PE header features using pefile library.
        Based on Malware-Detection project feature extraction.

        Returns:
            Dictionary of features or None if extraction fails
        """
        try:
            pe = pefile.PE(file_path)
            features = {}

            # DOS Header / File Header
            features['Machine'] = pe.FILE_HEADER.Machine
            features['SizeOfOptionalHeader'] = pe.FILE_HEADER.SizeOfOptionalHeader
            features['Characteristics'] = pe.FILE_HEADER.Characteristics

            # Optional Header
            features['MajorLinkerVersion'] = pe.OPTIONAL_HEADER.MajorLinkerVersion
            features['MinorLinkerVersion'] = pe.OPTIONAL_HEADER.MinorLinkerVersion
            features['SizeOfCode'] = pe.OPTIONAL_HEADER.SizeOfCode
            features['SizeOfInitializedData'] = pe.OPTIONAL_HEADER.SizeOfInitializedData
            features['SizeOfUninitializedData'] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
            features['AddressOfEntryPoint'] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
            features['BaseOfCode'] = pe.OPTIONAL_HEADER.BaseOfCode
            features['ImageBase'] = pe.OPTIONAL_HEADER.ImageBase
            features['SectionAlignment'] = pe.OPTIONAL_HEADER.SectionAlignment
            features['FileAlignment'] = pe.OPTIONAL_HEADER.FileAlignment
            features['MajorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion
            features['MinorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion
            features['SizeOfImage'] = pe.OPTIONAL_HEADER.SizeOfImage
            features['SizeOfHeaders'] = pe.OPTIONAL_HEADER.SizeOfHeaders
            features['CheckSum'] = pe.OPTIONAL_HEADER.CheckSum
            features['Subsystem'] = pe.OPTIONAL_HEADER.Subsystem
            features['DllCharacteristics'] = pe.OPTIONAL_HEADER.DllCharacteristics
            features['SizeOfStackReserve'] = pe.OPTIONAL_HEADER.SizeOfStackReserve
            features['SizeOfStackCommit'] = pe.OPTIONAL_HEADER.SizeOfStackCommit
            features['SizeOfHeapReserve'] = pe.OPTIONAL_HEADER.SizeOfHeapReserve
            features['SizeOfHeapCommit'] = pe.OPTIONAL_HEADER.SizeOfHeapCommit
            features['LoaderFlags'] = pe.OPTIONAL_HEADER.LoaderFlags
            features['NumberOfRvaAndSizes'] = pe.OPTIONAL_HEADER.NumberOfRvaAndSizes

            # Sections
            features['SectionsNb'] = len(pe.sections)
            if pe.sections:
                entropy = [sec.get_entropy() for sec in pe.sections]
                features['SectionsMeanEntropy'] = sum(entropy) / len(entropy)
                features['SectionsMinEntropy'] = min(entropy)
                features['SectionsMaxEntropy'] = max(entropy)

                raw_sizes = [sec.SizeOfRawData for sec in pe.sections]
                features['SectionsMeanRawsize'] = sum(raw_sizes) / len(raw_sizes)
                features['SectionsMinRawsize'] = min(raw_sizes)
                features['SectionsMaxRawsize'] = max(raw_sizes)

                virtual_sizes = [sec.Misc_VirtualSize for sec in pe.sections]
                features['SectionsMeanVirtualsize'] = sum(virtual_sizes) / len(virtual_sizes)
                features['SectionsMinVirtualsize'] = min(virtual_sizes)
                features['SectionMaxVirtualsize'] = max(virtual_sizes)

            # Imports/Exports
            features['ImportsNbDLL'] = len(pe.DIRECTORY_ENTRY_IMPORT) if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT') else 0
            features['ImportsNb'] = sum(len(imp.imports) for imp in pe.DIRECTORY_ENTRY_IMPORT) if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT') else 0
            features['ExportNb'] = len(pe.DIRECTORY_ENTRY_EXPORT.symbols) if hasattr(pe, 'DIRECTORY_ENTRY_EXPORT') else 0

            return features

        except Exception as e:
            logger.debug(f"Failed to extract PE features: {e}")
            return None

    # ------------------------------------------------------------------
    # URL Analysis
    # ------------------------------------------------------------------

    def _analyze_urls(self):
        """Extract and analyze URLs from all artifacts and text content."""
        urls = self._extract_urls_from_artifacts()
        logger.info(f"Found {len(urls)} unique URLs to analyze")

        # Whitelist of known safe domains
        whitelist = {'google.com', 'github.com', 'stackoverflow.com', 'microsoft.com', 'apple.com'}

        for url in urls:
            if url not in whitelist:
                self._analyze_single_url(url)

    def _extract_urls_from_artifacts(self) -> set:
        """Extract URLs from artifact metadata."""
        urls = set()
        conn = self.db.get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('SELECT metadata FROM artifacts WHERE metadata IS NOT NULL')
            rows = cursor.fetchall()

            for (metadata_json,) in rows:
                try:
                    metadata = json.loads(metadata_json) if isinstance(metadata_json, str) else metadata_json
                    if isinstance(metadata, dict):
                        # Search for URL patterns in metadata
                        urls.update(self._extract_urls_from_text(json.dumps(metadata)))
                except json.JSONDecodeError:
                    pass

        finally:
            conn.close()

        return urls

    def _extract_urls_from_text(self, text: str) -> set:
        """Extract URLs using regex pattern."""
        url_pattern = r'https?://[^\s]+|www\.[^\s]+'
        return set(re.findall(url_pattern, text))

    def _analyze_single_url(self, url: str):
        """Analyze a single URL for malicious indicators."""
        try:
            if self.use_docker_for_url:
                return self._analyze_url_with_docker(url)

            # Sanitize URL
            sanitized = self._sanitize_url(url)
            if not sanitized:
                return

            # Prepare for vectorizer
            url_data = [' '.join(sanitized)]

            # Predict
            vectorized = self.url_vectorizer.transform(url_data)
            prediction = self.url_classifier.predict(vectorized)[0]
            confidence = max(self.url_classifier.predict_proba(vectorized)[0])

            risk_level = MALWARE_RISK_LEVELS.get(str(prediction).lower(), 'MEDIUM')

            artifact_data = {
                "detection_type": "URL_MALWARE",
                "url": url,
                "classification": str(prediction),
                "confidence": float(confidence)
            }

            # Find associated file or create general artifact
            conn = self.db.get_connection()
            cursor = conn.cursor()
            try:
                # Store as artifact (not tied to specific file if not found)
                if prediction in ['malicious', 'bad']:
                    logger.info(f"URL Analysis: {url} -> {prediction} (confidence: {confidence:.2f})")
                    cursor.execute('''
                        INSERT INTO artifacts (file_id, pipeline_name, risk_level, description, metadata)
                        VALUES (NULL, ?, ?, ?, ?)
                    ''', (
                        self.PIPELINE_NAME,
                        risk_level,
                        f"Malicious URL Detected: {url}",
                        json.dumps(artifact_data)
                    ))
                    conn.commit()
            finally:
                conn.close()

        except Exception as e:
            logger.debug(f"URL analysis failed for {url}: {e}")

    def _analyze_single_pe_with_docker(self, file_id: int, file_path: str, file_hash: str):
        """Analyze a PE file using the Docker image."""
        from core.docker_runner import run_malware_pe

        result = run_malware_pe(self.docker_image, file_path, self.docker_timeout)
        if result.get("success") != "true":
            logger.warning(f"Docker PE analysis failed for {file_path}: {result.get('error')}")
            return

        label = self._parse_pe_docker_output(result.get("stdout", ""))
        if not label:
            logger.warning(f"Docker PE analysis output unrecognized for {file_path}")
            return

        risk_level = MALWARE_RISK_LEVELS.get(label, 'MEDIUM')

        artifact_data = {
            "detection_type": "PE_MALWARE_DOCKER",
            "classification": label,
            "confidence": 0.0,
            "file_hash": file_hash,
            "docker_image": self.docker_image,
        }

        if label in ['malicious', 'bad', 'suspicious']:
            self._store_artifact(
                file_id,
                risk_level,
                f"PE Malware Detection (Docker): {label}",
                artifact_data,
            )

        logger.info(
            f"Docker PE Analysis: {Path(file_path).name} -> {label}"
        )

    def _analyze_pe_with_docker(self, file_path: str) -> Dict[str, Any]:
        """Analyze a PE file using Docker and return a result dict."""
        from core.docker_runner import run_malware_pe

        result = run_malware_pe(self.docker_image, file_path, self.docker_timeout)
        if result.get("success") != "true":
            return {"error": result.get("error", "docker_failed")}

        label = self._parse_pe_docker_output(result.get("stdout", ""))
        if not label:
            return {"error": "unrecognized_docker_output"}

        return {
            "type": "pe",
            "file_path": file_path,
            "malicious": label in ['malicious', 'bad', 'suspicious'],
            "confidence": 0.0,
            "status": "malicious" if label in ['malicious', 'bad', 'suspicious'] else "safe",
            "label": label,
            "docker_image": self.docker_image,
        }

    def _analyze_url_with_docker(self, url: str) -> Dict[str, Any]:
        """Analyze a URL using Docker and store an artifact if needed."""
        from core.docker_runner import run_malware_url

        result = run_malware_url(self.docker_image, url, self.docker_timeout)
        if result.get("success") != "true":
            logger.warning(f"Docker URL analysis failed for {url}: {result.get('error')}")
            return {"error": result.get("error", "docker_failed")}

        label = self._parse_url_docker_output(result.get("stdout", ""))
        if not label:
            logger.warning(f"Docker URL analysis output unrecognized for {url}")
            return {"error": "unrecognized_docker_output"}

        if label in ['malicious', 'bad']:
            artifact_data = {
                "detection_type": "URL_MALWARE_DOCKER",
                "url": url,
                "classification": label,
                "confidence": 0.0,
                "docker_image": self.docker_image,
            }

            conn = self.db.get_connection()
            cursor = conn.cursor()
            try:
                cursor.execute('''
                    INSERT INTO artifacts (file_id, pipeline_name, risk_level, description, metadata)
                    VALUES (NULL, ?, ?, ?, ?)
                ''', (
                    self.PIPELINE_NAME,
                    MALWARE_RISK_LEVELS.get(label, 'MEDIUM'),
                    f"Malicious URL Detected (Docker): {url}",
                    json.dumps(artifact_data)
                ))
                conn.commit()
            finally:
                conn.close()

        return {
            "type": "url",
            "content": url,
            "malicious": label in ['malicious', 'bad'],
            "confidence": 0.0,
            "status": "malicious" if label in ['malicious', 'bad'] else "safe",
            "label": label,
            "docker_image": self.docker_image,
        }

    def _parse_pe_docker_output(self, output: str) -> Optional[str]:
        """Parse Docker PE output for label."""
        match = re.search(r"is\s+(malicious|legitimate)", output, re.IGNORECASE)
        if not match:
            return None
        label = match.group(1).lower()
        if label == "legitimate":
            return "good"
        return label

    def _parse_url_docker_output(self, output: str) -> Optional[str]:
        """Parse Docker URL output for label."""
        match = re.search(r"domain is:\s*([a-zA-Z]+)", output, re.IGNORECASE)
        if not match:
            return None
        return match.group(1).lower()

    def _sanitize_url(self, url: str) -> List[str]:
        """
        Tokenize URL for machine learning model.
        Based on Malware-Detection project sanitization.
        """
        try:
            url = url.lower()
            tokens = []
            
            # Split by slashes
            for slash_part in url.split('/'):
                # Split by hyphens
                for hyphen_part in slash_part.split('-'):
                    # Split by dots
                    tokens.extend(hyphen_part.split('.'))
            
            # Remove duplicates and empty strings
            tokens = list(set([t for t in tokens if t]))
            
            # Remove common TLDs
            tokens = [t for t in tokens if t not in ['com', 'org', 'net', 'edu', 'gov']]
            
            return tokens
        except Exception as e:
            logger.debug(f"URL sanitization failed: {e}")
            return []

    # ------------------------------------------------------------------
    # Database Operations
    # ------------------------------------------------------------------

    def _store_artifact(
        self,
        file_id: int,
        risk_level: str,
        description: str,
        metadata: Dict[str, Any]
    ):
        """Store analysis artifact in database."""
        conn = self.db.get_connection()
        try:
            conn.execute('''
                INSERT INTO artifacts (file_id, pipeline_name, risk_level, description, metadata)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                file_id,
                self.PIPELINE_NAME,
                risk_level,
                description,
                json.dumps(metadata)
            ))
            conn.commit()
        finally:
            conn.close()
